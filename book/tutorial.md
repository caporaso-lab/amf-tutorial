(tutorial)=
# Tutorial

## Installing QIIME 2
:::{note}
This document was built with its own conda environment.
You can download the environment file that was used from the download link on the top-right of this article.
:::

This tutorial uses the command line interface or cli. If you are uncomfortable with using the cli, [this](https://drive.google.com/file/d/1syrgAHkO6fbtHgIYWochwpWTEarrBSLG/view) video serves as an introduction to basic cli usage.

Make sure you have conda installed by running the command `conda --version`. If you do not have conda installed follow the instructions [here](https://library.qiime2.org/quickstart/amplicon#id-1-installing-miniconda).

<!-- TODO: When there is a release of amplicon that has q2-fondue use that here maybe? Would need the whole per architecture instructions then right? -->

```
conda env create -n q2-amf-tutorial -f https://raw.githubusercontent.com/caporaso-lab/amf-tutorial/refs/heads/main/book/_static/environment.yml
conda activate q2-amf-tutorial
```

In order to use q2-fondue, you will first need to configure fondue. Instructions for doing so may be found [here](https://library.qiime2.org/plugins/bokulich-lab/q2-fondue#mandatory-configuration-for-all-three-options).

## Sample metadata

This study investigates differences in AMF communities between modern high-yielding rice varieties (BR28, BR29, BR58) and local traditional varieties (Shampakatar, Ushapari), sampled from eight rice fields with five soil samples each. A total of 200 samples were collected, of which subsample of  143 AMF-relevant samples (79 from modern and 64 from traditional varieties), to test the hypothesis recorded in the metadata file.
Before starting the analysis, explore the sample metadata to familiarize yourself with the samples used in this study. The following command will download the sample metadata as tab-separated text and save it in the file sample-metadata.tsv. This sample-metadata.tsv file is used throughout the rest of the tutorial.

:::{describe-usage}
:scope: amf-tutorial
metadata = use.init_metadata_from_url('metadata',
                                   'https://www.dropbox.com/scl/fi/zgcnuetdxochydkb0o3bw/metadata_file_rice.tsv?rlkey=fo5ywq8549fn5optv1u1nh4m4&st=hzljxvx3&dl=1')
:::

## Obtaining the data
In this tutorial, we will use [q2-fondue](https://library.qiime2.org/plugins/bokulich-lab/q2-fondue) to download our publicly available data and import them into QIIME 2. The data we use in this tutorial has already been imported into QIIME 2 for you. [This](https://drive.google.com/file/d/1noyVVSz2U-UG_ev72I7q7ysDoNlm4Ijk/view?usp=sharing) video gives a basic overview of what importing data into QIIME 2 using a manifest file looks like.

First, letâ€™s download the metadata containing the NCBI SRA project, accession number SRR13445888.

:::{describe-usage}
project_accession = use.init_artifact_from_url('project-accession',
                                              'https://www.dropbox.com/scl/fi/h470qev6vqrzir3f7yksk/project_id.qza?rlkey=ra7jno6nzs0m2ddkynvgt3w14&st=rmpx5ndn&dl=1')
:::
Then we can visualize it using `qiime metadata tabulate`.

:::{describe-usage}

project_accession_md = use.view_as_metadata('project_accession_md', project_accession)

use.action(
    use.UsageAction(plugin_id='metadata',
                    action_id='tabulate'),
    use.UsageInputs(input=project_accession_md),
    use.UsageOutputNames(visualization='project-accession'))
:::

We can use q2-fondue ðŸ«• to easily import the data using this command:

<!-- TODO: Remove this when/if fixed -->

:::{warning}
There is currently an issue with fondue preventing this command from running correctly. For now, simply run the wget command above.
:::

```
qiime fondue get-sequences \
    --i-accession-ids project-accession.qza \
    --p-email [Insert Your Email] \
    --o-single-reads single-reads-demux.qza \
    --o-paired-reads demux.qza \
    --o-failed-runs failed-runs.qza
```

or you can download the demux artifact here:

:::{describe-usage}
demux = use.init_artifact_from_url('demux',
                                   'https://www.dropbox.com/scl/fi/81fwmwgymuq1ae4o18xpb/subsampled_demux.qza?rlkey=yyzr6inkmt85xv6i54d7qitml&st=3pjj0kd5&dl=1')
:::
Now, letâ€™s visualize our data using demux summarize to assess sequencing quality.

:::{note}
In QIIME 2, all data is structured as an Artifact of a specific semantic type. Artifacts contain the data as well as information about the data, including a record of the original data and the tools used to process it. This allows for better tracking of how you actually got to where you are in your analysis. You can learn more about common QIIME 2 Artifacts and semantic types here.
:::

:::{describe-usage}
use.action(
    use.UsageAction(plugin_id='demux',
                    action_id='summarize'),
    use.UsageInputs(data=demux),
    use.UsageOutputNames(visualization='demux'))
:::

### Understanding the Data

If you downloaded your data from NCBI-SRA, or received it from a sequencing facility, you will typically need three key files:

Metadata file â€“ This mapping file provides contextual information about your experiment, including hypotheses, treatments, and sample details.

Classifier file â€“ Used for assigning taxonomy during analysis.

Sequence files â€“ These are usually in FASTQ format or already imported into QIIME 2 as .qza files.

To begin exploring your data and assessing its quality, open the `demux.qzv` file in QIIME 2 View. This visualization helps you evaluate read quality, which is critical for determining appropriate trimming parameters in downstream steps.

## Revision Questions

1. What is the minimum and maximum number of reads in our samples?

2. Do any of the samples have fewer than 1,000 sequences?

3. At which position does the median quality score drop below 30?

Note: If any of the samples have very few sequences (e.g., fewer than 1,000), you may want to omit them from downstream analysis, as they could negatively affect data interpretation.

# Denoising Using DADA2
Denoising is the process of correcting errors in the sequencing data and delimitating ASVs (amplicon sequence variants). The Non-biological sequences (e.g., adapters, primers, linker pads, etc.) and errors created by sequencing machines, such as incorrect base calls or random noise which can lead to inaccurate results if not corrected. For a more detailed lecture on this process, watch [this](https://drive.google.com/file/d/12ji91W-DAew_z9dGc6D0aDtpWEqe-m8l/view?usp=sharing) video.

:::{describe-usage}
table, denoising_stats, representative_sequences = use.action(
    use.UsageAction(plugin_id='dada2', action_id='denoise_paired'),
    use.UsageInputs(
        demultiplexed_seqs=demux,
        trunc_len_f=240,
        trunc_len_r=220,
        ),
    use.UsageOutputNames(
        table='table',
        denoising_stats='denoising_stats',
        representative_sequences='representative_sequences'
        )
)
:::

## Revision Questions
1.  How did we decide the truncation parameters, --p-trunc-len-f 240 --p-trunc-len-r 220?
Hint: At what base pair does the median quality drop below 30?

:::{describe-usage}
denoising_stats_md = use.view_as_metadata('denoising_stats_md', denoising_stats)

dada2_stats_viz = use.action(
    use.UsageAction(plugin_id='metadata', action_id='tabulate'),
    use.UsageInputs(
        input=denoising_stats_md),
    use.UsageOutputNames(visualization='stats-dada2'))
:::

Note- If a large number (e.g. >50%) of sequences are lost during denoising/filtering the settings may be too stringent.

:::{describe-usage}
rep_seqs_viz = use.action(
    use.UsageAction(plugin_id='feature_table', action_id='tabulate_seqs'),
    use.UsageInputs(
        data=representative_sequences),
    use.UsageOutputNames(visualization='rep-seqs'))
:::
## Revision Questions

1. Do BLAST searches of the representative sequences make sense? Are the features what you would expect like AMF or not?
2. How many features (ASVs) were generated? Are the communities high or low diversity?

:::{describe-usage}
table_summary = use.action(
    use.UsageAction(plugin_id='feature_table', action_id='summarize'),
    use.UsageInputs(
        table=table),
    use.UsageOutputNames(visualization='table'))
:::

# Taxonomic assignment

In order to understand which microbes are in the environment we sampled, we need to taxonomically annotate our sequences. More information on this process may be found [here](https://drive.google.com/file/d/1awHVwbNUt6_PeFy7uzhSIRTXHIgIbMB8/view?usp=sharing).

## Classifications with fit-classifier-naive-bayes

To construct a taxonomic classifier using the MaarjAM database, two primary input files are required:

1. A FASTA file containing the reference sequences
2. A taxonomy file mapping those sequences to their taxonomic lineages

These resources can be downloaded from [the official MaarjAM database website](https://maarjam.ut.ee/?action=bDownload). Alternatively, pre-imported .qza files are also be downloaded from here:

:::{describe-usage}
def maarjam_refseq_factory():
    from urllib import request
    from qiime2 import Artifact
    # Download the FASTA file
    fp, _ = request.urlretrieve(
        'https://www.dropbox.com/scl/fi/degicmkcyidve4qc3z3jh/maarjam_ref_seq.qza?rlkey=klzt244f0jylqeloxwqp61tb2&st=v6vpxfr0&dl=1')
    # Import as a QIIME 2 artifact
    return Artifact.load(fp)

maarjam_ref_seq = use.init_artifact('maarjam_ref_seq', maarjam_refseq_factory)
:::

:::{describe-usage}
def maarjam_taxonomy_factory():
    from urllib import request
    from qiime2 import Artifact
    # Download the taxonomy TSV file
    fp, _ = request.urlretrieve(
        'https://www.dropbox.com/scl/fi/93gm5lfsn8kli2elemigs/ref-taxonomy.qza?rlkey=afvwcqdjgotn21ermz9rx015c&st=1fhecg2i&dl=1')
    # Import as a QIIME 2 artifact
    return Artifact.load(fp)

ref_taxonomy_maarjam = use.init_artifact('ref_taxonomy_maarjam', maarjam_taxonomy_factory)

:::

Next step is building the classifier file. Building an accurate classifier file is crucial for reliable taxonomic analysis, as it can significantly influence your results. An incorrect or poorly trained classifier may lead to unassigned or misclassified sequences. It's recommended to run your data using both the [vsearch](https://amplicon-docs.qiime2.org/en/latest/references/plugins/vsearch.html#q2-plugin-vsearch) and [sklearn](https://amplicon-docs.qiime2.org/en/latest/references/plugins/sample-classifier.html) methods for comparison.

```code
qiime feature-classifier fit-classifier-naive-bayes \
    --i-reference-reads maarjam-ref-seq.qza \
    --i-reference-taxonomy ref-taxonomy-maarjam.qza \
    --o-classifier classifier-maarjam.qza
```

:::{note}
Due to time constraints, this command is not generated in this notebook. The resulting artifacts can be generated by running this command or running wget the artifact below. ðŸ‘‡
:::

:::{describe-usage}
classifier_maarjam = use.init_artifact_from_url('classifier_maarjam',
                                   'https://www.dropbox.com/scl/fi/bh65ab79wmo9calgiwsxr/classifier-maarjam-1.qza?rlkey=rxegaem82jpclb8e40fp019ru&st=ludlvgxt&dl=1')
:::

```code
qiime feature-classifier classify-sklearn \
    --i-reads representative-sequences.qza \
    --i-classifier classifier-maarjam.qza \
    --p-confidence 0.7 \
    --o-classification taxonomy-maarjam.qza
```

:::{describe-usage}
taxonomy_maarjam = use.init_artifact_from_url('taxonomy_maarjam',
                                   'https://www.dropbox.com/scl/fi/9zpv1fg8nsrcaj0v0oarb/taxonomy-maarjam-subsampled.qza?rlkey=rhzuw7mgz94hz85jx8see82q8&st=3t5cjlc3&dl=1')
:::

:::{describe-usage}
taxonomy_maarjam_md = use.view_as_metadata('taxonomy_maarjam_md', taxonomy_maarjam)
use.action(
    use.UsageAction(plugin_id='metadata', action_id='tabulate'),
    use.UsageInputs(
        input=taxonomy_maarjam_md),
    use.UsageOutputNames(
        visualization='taxonomy_maarjam_md'))
:::

For convenience value of `p-confidence` is kept 0.7; however, it would be ideal to keep this at 0.97.

## Revision Questions

1.  How many of your ASVs were taxonomically assigned?
   note :view your taxonomy.qzv file

2.  What was the difference in the number of ASVs when you used `p-confidence` of 0.97

## Classifications with classify-consensus-vsearch
### Classification with maarjAM
:::{describe-usage}
rice_taxonomy_vsearch, rice_search_results_vsearch = use.action(
    use.UsageAction(plugin_id='feature_classifier', action_id='classify_consensus_vsearch'),
    use.UsageInputs(
        query=representative_sequences,
        reference_reads=maarjam_ref_seq,
        reference_taxonomy=ref_taxonomy_maarjam,
        maxaccepts=1,
        perc_identity=0.7,
        strand='both',
        top_hits_only=True,
        unassignable_label='Unassigned'),
    use.UsageOutputNames(
        classification='rice_taxonomy_vsearch',
        search_results='rice_search_results_vsearch'))
:::

:::{describe-usage}
rice_taxonomy_vsearch = use.view_as_metadata('rice_taxonomy_vsearch', rice_taxonomy_vsearch)
use.action(
    use.UsageAction(plugin_id='metadata', action_id='tabulate'),
    use.UsageInputs(
        input=rice_taxonomy_vsearch),
    use.UsageOutputNames(
        visualization='rice_taxonomy_vsearch'))
:::

## Revision Questions

1. How many of your ASVs were taxonomically assigned by this method. Is there a difference in output between fit-classifier-naive-bayes and classify-consensus-vsearch?

## Taxonomy Bar Plot

The output of of `feature-classifier classify-sklearn` is used for the rest of the tutorial over the `vsearch` output.

:::{describe-usage}
taxa_bar_plots = use.action(
    use.UsageAction(plugin_id='taxa', action_id='barplot'),
    use.UsageInputs(
        table=table,
        taxonomy=taxonomy_maarjam,
        metadata=metadata),
    use.UsageOutputNames(visualization='taxa_bar_plots'))
:::

## Revision Questions
1. What are the dominant phyla in each inÂ each group ?

Visualize the samples atÂ Level 6Â (which corresponds to the genus of AMF in this analysis), and then sort the samples byÂ  env_broad_level,  You can add as many taxonomic levels levels you want.
If it's hard to visualize the dominant phyla in each inÂ each group, download the csv file on left hand side and use this to plot a relative abundance chart.

## Filtering Tables

You can filter table if you want to work with specific group of taxa. You can create separate files for traditional and modern varieties if you want to.

:::{describe-usage}
traditional_rice_table, = use.action(
    use.UsageAction(plugin_id='feature_table', action_id='filter_samples'),
    use.UsageInputs(
        table=table,
        metadata=metadata,
        where="[env_broad_scale]='Traditional rice root'"),
    use.UsageOutputNames(filtered_table='traditional_rice_table'))
:::

:::{describe-usage}
traditional_rice_table_viz = use.action(
    use.UsageAction(plugin_id='feature_table', action_id='summarize'),
    use.UsageInputs(
        table=traditional_rice_table),
    use.UsageOutputNames(visualization='traditional_rice_table'))
:::

:::{describe-usage}
modern_rice_table, = use.action(
    use.UsageAction(plugin_id='feature_table', action_id='filter_samples'),
    use.UsageInputs(
        table=table,
        metadata=metadata,
        where="[env_broad_scale]='Modern rice root'"),
    use.UsageOutputNames(filtered_table='modern_rice_table'))
:::

:::{describe-usage}
modern_rice_table_viz = use.action(
    use.UsageAction(plugin_id='feature_table', action_id='summarize'),
    use.UsageInputs(
        table=modern_rice_table),
    use.UsageOutputNames(visualization='modern_rice_table'))
:::

# Differential abundance (ANCOM-BC)
Accurately identifying features that are differentially abundant across sample types in microbiome data is a challenging problem and an open area of research. Analysis of Compositions of Microbiomes with Bias Correction (ANCOM-BC) isÂ a methodology for differential abundance (DA) testing that corrects bias in microbiome data. Here we will use ANCOM-BC to identify taxa that are differentially abundant in modern or traditional rice varieties. For more information on this process watch [this](https://drive.google.com/file/d/1QVXHvtzTUYa1Z195oDbBSnwN265fPaL2/view?usp=sharing) video.

We need to filter our table so we can investigate only Glomeromycetes class features.

:::{describe-usage}
glomeromycetes_table, = use.action(
    use.UsageAction(plugin_id='taxa', action_id='filter_table'),
    use.UsageInputs(
        table=table,
        taxonomy=taxonomy_maarjam,
        include='c__Glomeromycetes'),
    use.UsageOutputNames(filtered_table='glomeromycetes_table'))
:::

:::{describe-usage}
collapsed_table_level_6, = use.action(
    use.UsageAction(plugin_id='taxa', action_id='collapse'),
    use.UsageInputs(
        table=glomeromycetes_table,
        taxonomy=taxonomy_maarjam,
        level=6),
    use.UsageOutputNames(collapsed_table='collapsed_table_level_6'))
:::

:::{describe-usage}
l6_ancombc_differentials, = use.action(
    use.UsageAction(plugin_id='composition', action_id='ancombc'),
    use.UsageInputs(
        table=collapsed_table_level_6,
        metadata=metadata,
        formula='env_broad_scale'),
    use.UsageOutputNames(differentials='l6_ancombc_differentials'))
:::

:::{describe-usage}
l6_da_barplot = use.action(
    use.UsageAction(plugin_id='composition', action_id='da_barplot'),
    use.UsageInputs(
        data=l6_ancombc_differentials,
        significance_threshold=0.05,
        level_delimiter=';'),
    use.UsageOutputNames(visualization='l6_da_barplot'))
:::
## Revision Questions

1. Which taxa are enriched in traditional varieties?
Note: try changing sample_name to column 'env_broad_scale'; try with significance threshold of 0.01 also.

# Diversity Analysis

Now let's investigate community richness i.e. alpha diversity and the compositional differences of the AMF communities associates with different rice varieties i.e. beta diversity. Watch [this](https://drive.google.com/file/d/1NYqlfypFqKmf20r8VAaokvvMCNts7RI0/view?usp=sharing) video for more information.

## Phylogenetic tree

Both rooted and unrooted trees can be generated by this command.
:::{describe-usage}
rooted_tree, unrooted_tree, aligned_rep_seqs, masked_aligned_rep_seqs = use.action(
    use.UsageAction(plugin_id='phylogeny', action_id='align_to_tree_mafft_fasttree'),
    use.UsageInputs(
        sequences=representative_sequences,
        ),
    use.UsageOutputNames(
        rooted_tree='rooted_tree',
        tree='unrooted_tree',
        alignment='aligned_rep_seqs',
        masked_alignment='masked_aligned_rep_seqs'))
:::

## Alpha rarefaction Plot

:::{describe-usage}
alpha_rarefaction_plot = use.action(
    use.UsageAction(plugin_id='diversity', action_id='alpha_rarefaction'),
    use.UsageInputs(
        table=table,
        phylogeny=rooted_tree,
        max_depth=1321,
        metadata=metadata,
        steps=4,
        iterations=4
        ),
    use.UsageOutputNames(visualization='alpha_rarefaction'))
:::
## Revision Questions

1. How did we decide as maximum depth 1321 ?

The max depth setting will depend on the number of sequences in your samples. The value that you provide for â€“p-max-depth should be determined by reviewing the OTU Frequency per sample information presented in theÂ `table.qzv` file that was created above. Also observe that, do the refraction curves for each sample plateau? If they donâ€™t, the samples havenâ€™t been sequenced deeply enough to capture the full diversity of the AM fungal communities, which is shown on the y-axis. At what sequencing depth (x-axis) do your curves plateau? This value will be important for downstream analyses, particularly for alpha diversity analyses. Considering both features and samples retained is very important.

You may want to increase that value if the lines in the resulting rarefaction plot donâ€™t appear to be leveling out, or decrease that value if you seem to be losing many of your samples due to low total frequencies closer to the minimum sampling depth than the maximum sampling depth.

:::{describe-usage}
core_metrics_outputs = use.action(
    use.UsageAction(plugin_id='diversity', action_id='core_metrics_phylogenetic'),
    use.UsageInputs(
        table=table,
        phylogeny=rooted_tree,
        sampling_depth=401,
        metadata=metadata,
        ),
    use.UsageOutputNames(
        evenness_vector='evenness_vector',
        faith_pd_vector='faith_pd_vector',
        unweighted_unifrac_distance_matrix='unweighted_unifrac_distance_matrix',
        bray_curtis_pcoa_results='bray-curtis-pcoa-results',
        shannon_vector='shannon_vector',
        rarefied_table='rarefied-table',
        weighted_unifrac_distance_matrix='weighted-unifrac-distance-matrix',
        jaccard_pcoa_results='jaccard-pcoa-results',
        unweighted_unifrac_emperor='unweighted-unifrac-emperor',
        weighted_unifrac_pcoa_results='weighted-unifrac-pcoa-results',
        observed_features_vector='observed-features-vector',
        jaccard_distance_matrix='jaccard-distance-matrix',
        jaccard_emperor='jaccard-emperor',
        bray_curtis_emperor='bray-curtis-emperor',
        weighted_unifrac_emperor='weighted-unifrac-emperor',
        bray_curtis_distance_matrix='bray-curtis-distance-matrix',
        unweighted_unifrac_pcoa_results='unweighted-unifrac-pcoa-results'))
:::
## Alpha Diversity and Community Richness
:::{describe-usage}
shannon_group_significance = use.action(
    use.UsageAction(plugin_id='diversity', action_id='alpha_group_significance'),
    use.UsageInputs(
        alpha_diversity=core_metrics_outputs.shannon_vector,
        metadata=metadata),
    use.UsageOutputNames(visualization='shannon_group_significance'))
:::

:::{describe-usage}
evenness_group_significance = use.action(
    use.UsageAction(plugin_id='diversity', action_id='alpha_group_significance'),
    use.UsageInputs(
        alpha_diversity=core_metrics_outputs.evenness_vector,
        metadata=metadata),
    use.UsageOutputNames(visualization='evenness_group_significance'))
:::

:::{describe-usage}
faith_pd_group_significance = use.action(
    use.UsageAction(plugin_id='diversity', action_id='alpha_group_significance'),
    use.UsageInputs(
        alpha_diversity=core_metrics_outputs.faith_pd_vector,
        metadata=metadata),
    use.UsageOutputNames(visualization='faith_group'))
:::

## Revision Questions
1. Is species richness same as number of ASVs ?

## Beta Diversity

:::{describe-usage}

env_broad_col = use.get_metadata_column('env_broad_scale', 'env_broad_scale', metadata)

beta_group_significance_simple = use.action(
    use.UsageAction(plugin_id='diversity', action_id='beta_group_significance'),
    use.UsageInputs(
        distance_matrix=core_metrics_outputs.unweighted_unifrac_distance_matrix,
        metadata=env_broad_col,
        method='permanova',
        pairwise=True,
        permutations=999),
    use.UsageOutputNames(visualization='unweighted_unifrac_env_broad_scale_significance'))
:::

:::{describe-usage}

sample_name_col = use.get_metadata_column('Sample_Name', 'Sample_Name', metadata)

beta_group_significance = use.action(
    use.UsageAction(plugin_id='diversity', action_id='beta_group_significance'),
    use.UsageInputs(
        distance_matrix=core_metrics_outputs.unweighted_unifrac_distance_matrix,
        metadata=sample_name_col,
        method='permanova',
        pairwise=True,
        permutations=999),
    use.UsageOutputNames(visualization='unweighted_unifrac_sample_name_significance'))
:::
